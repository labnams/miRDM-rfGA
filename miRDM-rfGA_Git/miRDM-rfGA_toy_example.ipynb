{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toyexample of miRDM-rfGA with toydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load package\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from deap import creator, base, tools, algorithms\n",
    "import sys\n",
    "\n",
    "# random sampling\n",
    "from random import sample\n",
    "\n",
    "# combination\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "#warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter settings based on setting 5\n",
    "random.seed(42)\n",
    "_functional_relevance_lookup_dict = {}\n",
    "_population = 1000\n",
    "_generation = 300\n",
    "_penalty_weight = 7\n",
    "_num_one = 12\n",
    "# _mu = 50\n",
    "# _lambda = 100\n",
    "_cxpb = 0.8\n",
    "_mutpb = 0.003\n",
    "\n",
    "# def trim_newline(s):\n",
    "#     if s[-1] == '\\n':\n",
    "#         return s[0:-1]\n",
    "    \n",
    "#     return s\n",
    "\n",
    "# workdir = \"D://miR_Rank_Feautre_selection//GA_test\"\n",
    "# _functional_relevance_lookup_dict = {}\n",
    "# with open(workdir + '//FR.txt', 'r') as fh:\n",
    "#     fh.readline() # skip the first line\n",
    "#     for line in fh:\n",
    "#         elements = line.split('\\t')\n",
    "#         _functional_relevance_lookup_dict[elements[0]] = float(trim_newline(elements[1]))\n",
    "\n",
    "# def functional_relevance_score(items):\n",
    "#     sum_scores = 0\n",
    "#     for x in items:\n",
    "#         try:\n",
    "#             sum_scores += _functional_relevance_lookup_dict[x]\n",
    "#         except KeyError:\n",
    "#             continue\n",
    "    \n",
    "#     return sum_scores\n",
    "\n",
    "\n",
    "# Define fitness function\n",
    "def average(l):\n",
    "    \"\"\"\n",
    "    Returns the average between list elements\n",
    "    \"\"\"\n",
    "    return (sum(l)/float(len(l)))\n",
    "\n",
    "\n",
    "def evaluate(individual, X, y):\n",
    "#     print (individual)\n",
    "#     print (\"Indivdial: num of 0: %d \" % individual.count(0))\n",
    "#     print (\"Indivdial: num of 1: %d \" % individual.count(1))\n",
    "#     print (\"The num of genes: %d\" % len(individual))\n",
    "    if(individual.count(0) != len(individual)):\n",
    "        # 조건 1: 1의 개수가 5보다 클 때, penalty 값을 \n",
    "        \n",
    "        # get index with value 0\n",
    "        cols = [i for i in range(len(individual)) if individual[i] == 1]\n",
    "\n",
    "        \n",
    "        #if len(individual) - len(cols) < 5:\n",
    "        #    return 10000, 10000, 10000\n",
    "        \n",
    "        #if len(individual) - len(cols) > 20:\n",
    "        #    return 10000, 10000, 10000\n",
    "        \n",
    "        # get features subset\n",
    "#         X_parsed = X.drop(X.columns[cols], axis=1)\n",
    "#         X_subset = pd.get_dummies(X_parsed)\n",
    "\n",
    "        # apply classification algorithm\n",
    "        clf = RandomForestClassifier()\n",
    "        #clf = LogisticRegression()\n",
    "        \n",
    "        # fr_score = functional_relevance_score(X_parsed.columns.to_list())\n",
    " \n",
    "        avg_roc_score = 100 * average(cross_val_score(clf, X.iloc[:,cols], y, cv=3, scoring='roc_auc'))\n",
    "        penalty_function = _penalty_weight * abs(individual.count(1) - 3)\n",
    "#         print(\"Avg roc score: \" + str(avg_roc_score) + \" Penalty weight: \" + str(penalty_function) + \" len 1: \" + str(individual.count(1)))\n",
    "        # return average(cross_val_score(clf, X_subset, y, cv=5), scoring = \"roc_auc\") - _penalty_weight * abs(individual.count(1) - 3), 1/fr_score #, (len(individual) - len(cols)) / len(individual)\n",
    "        return avg_roc_score - penalty_function,\n",
    "#         shuffle = cross_validation.KFold(len(X), n_folds=3, shuffle=True)\n",
    "#         scores = cross_val_score(rf, X, y, cv=shuffle, scoring='roc_auc')\n",
    "    else:\n",
    "        # return 10000, 10000 #, 10000\n",
    "        return -100000,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data path\n",
    "workdir = \"./toydata\" # toydata path\n",
    "# toy miRNA-Seq data loading\n",
    "df_genomic = pd.read_csv(workdir + \"//toydata.csv\"\n",
    "                    , index_col = [\"id\"])\n",
    "y = df_genomic[\"Class\"] #Class\n",
    "#X_DN = df_e1.drop([\"Class\", 'hsa-let-7b-5p', 'hsa-miR-23b-3p', 'hsa-let-7c-5p', 'hsa-miR-30a-3p', 'hsa-miR-200c-3p'], axis = 1) #Rest dataseet\n",
    "#X_DN = df_e1.drop([\"Class\", 'hsa-miR-1290'], axis = 1) #Rest dataseet\n",
    "#X_DN = df_e1.drop([\"Class\", 'hsa-miR-642a-5p', 'hsa-miR-1343-3p', 'hsa-miR-642a-3p', 'hsa-miR-99b-3p', 'hsa-miR-671-3p', 'hsa-miR-3144-5p', 'hsa-miR-320c', 'hsa-miR-150-5p'], axis = 1) #Rest dataseet\n",
    "#X_DN = df_e1.drop([\"Class\", 'hsa-miR-642a-5p', 'hsa-miR-642a-3p', 'hsa-miR-99b-3p', 'hsa-miR-891a-5p', 'hsa-miR-320c', 'hsa-miR-150-5p'], axis = 1) #Rest dataseet\n",
    "df_genomic = df_genomic.drop([\"Class\"], axis = 1) #Rest dataseet\n",
    "# split data train 70 % and test 30 %\n",
    "#drop and rotate dataset\n",
    "df_genomic = df_genomic.T[(df_genomic != 0).any()].T\n",
    "\n",
    "_number_of_samples = len(df_genomic)\n",
    "_number_of_items = len(df_genomic.columns.to_list())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_genomic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove sparse miRNAs\n",
    "cut_off = 0.9\n",
    "for x in df_genomic.columns:\n",
    "    try:\n",
    "        num_zero = df_genomic[x].value_counts(0)[0]\n",
    "        if num_zero / _number_of_samples > cut_off:\n",
    "            df_genomic = df_genomic.drop([x], axis = 1)\n",
    "    except KeyError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genomic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data excluding labels\n",
    "X = df_genomic.iloc[:,]\n",
    "\n",
    "# z-normalization\n",
    "X = (X - X.mean())/X.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GA toolbox setup\n",
    "creator.create(\"MyFitnessMulti\", base.Fitness, weights=(1.0,)) # Note here <- I used only two weights!  (at first, I tried weights=(-1.0 , -1.0, 1.0)) but it crashes. With deap, you cannot do such a thing.\n",
    "creator.create(\"Individual\", list, fitness=creator.MyFitnessMulti)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "#def f(a, b, c): \n",
    "#    return np.random.choice(np.arange(a, b), p=c)\n",
    "  \n",
    "# A partial function that calls f with \n",
    "# a as 3, b as 1 and c as 4. \n",
    "#g = partial(f, 0, 2) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Attribute generator\n",
    "def random_individual_three():\n",
    "    zero_list = [0 for i in range(len(X.columns))]\n",
    "    index_for_one = np.random.choice(len(X.columns), _num_one, replace=True)\n",
    "#     index_for_one = random.sample(range(len(X.columns)),_num_one) # 중복을 허용하지 않는 index random sampling\n",
    "    # index_for_one = list(combinations(range(len(X.columns)),_num_one)) # combination 생성\n",
    "    for i in index_for_one:\n",
    "        zero_list[i]= 1 \n",
    "    \n",
    "#     print(zero_list.count(1))\n",
    "    return zero_list\n",
    "    \n",
    "\n",
    "# Structure initializers\n",
    "toolbox.register(\"rand_ind\",random_individual_three)\n",
    "toolbox.register(\"individual\", tools.initIterate, creator.Individual\n",
    "                 ,toolbox.rand_ind) #, n=30) #\n",
    "# toolbox.register(\"individual\", tools.initIterate, creator.Individual, random.sample(range(len(X.columns)),_num_one))\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "# Registration of crossover & mutation functions\n",
    "#toolbox.register(\"mate\", tools.cxUniform, indpb=0.8)\n",
    "toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=_mutpb)\n",
    "\n",
    "# Registration of selection function\n",
    "toolbox.register(\"select\", tools.selBest)\n",
    "# toolbox.register(\"select\", tools.selRoulette)\n",
    "# toolbox.register(\"select\", tools.selNSGA2) # NSGA-2 applies to multi-objective problems such as knapsack problem\n",
    "# toolbox.register(\"select\", tools.selTournament, k=1, tournsize=3)\n",
    "\n",
    "toolbox.register(\"evaluate\", evaluate, X=X, y=y)\n",
    "logbook = tools.Logbook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functools import partial\n",
    "# random.seed(42)\n",
    "# gen_idx = random.sample(range(len(X.columns)), _num_one)\n",
    "# print(gen_idx)\n",
    "# print(list(gen_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pop = toolbox.population(n=_population)\n",
    "hof = tools.HallOfFame(1) # a ParetoFront may be used to retrieve the best non dominated individuals of the evolution\n",
    "# hof = tools.ParetoFront() # a ParetoFront may be used to retrieve the best non dominated individuals of the evolution\n",
    "\n",
    "# assign statistics for fitness function in each population\n",
    "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats.register(\"avg\", np.mean, axis=0)\n",
    "stats.register(\"std\", np.std, axis=0)\n",
    "stats.register(\"min\", np.min, axis=0)\n",
    "stats.register(\"max\", np.max, axis=0)\n",
    "\n",
    "# pop, log = algorithms.eaMuPlusLambda(pop, toolbox, _mu, _lambda, _cxpb, _mutpb, \n",
    "#                                      ngen=_generation, stats=stats, halloffame=hof) #, verbose=True)\n",
    "\n",
    "# pop, log = algorithms.eaSimple(pop, toolbox, cxpb=_cxpb, mutpb=_mutpb, ngen=_generation, \n",
    "#                                   stats=stats, halloffame=hof, verbose=True)\n",
    "\n",
    "# to check individuals in each popluation\n",
    "population = []\n",
    "\n",
    "# Run GA\n",
    "for i in range(0,_generation + 1):\n",
    "    print (\"Generation: %d\" % i)\n",
    "    pop, log = algorithms.eaSimple(pop, toolbox, cxpb=_cxpb, mutpb=_mutpb, ngen=1, stats=stats, halloffame=hof, verbose=True)\n",
    "    population.append(pop)\n",
    "# pop, log = algorithms.eaSimple(pop, toolbox, cxpb=_cxpb, mutpb=_mutpb, ngen=_generation, stats=stats, halloffame=hof, verbose=True)\n",
    "\n",
    "#for ind, fit in zip (pop, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Individulas in the hall of fame population\")\n",
    "for x in hof:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The # of individuals in the hof population: %d \" % len(hof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of the best individual\n",
    "_individual = tools.selBest(hof, 1)[0]\n",
    "# _individual = tools.selNSGA2(hof, 1)[0]\n",
    "_individual_features = [X.columns[i] for i in range(len(_individual)) if _individual[i] == 1]\n",
    "print(\"The best individual is :\" + str(_individual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The best features are: \\t\" + str(_individual_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fitness score of best individual\n",
    "print('Fitness score: \\t' + str(_individual.fitness))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of Features in Subset: \\t' + str(_individual.count(1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Individual: \\t' + str(_individual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Feature Subset\\t: ' + str(_individual_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_individual.fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(_individual_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for x in _individual_features:\n",
    "    print (\"'{0}', \".format(x), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_individual.count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
